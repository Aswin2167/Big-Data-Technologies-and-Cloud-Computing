{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<body>\n",
        "  <center>\n",
        "    <img align=\"center\" src=\"https://duk.ac.in/wp-content/uploads/2021/03/logo_transparent_bg_caption.png\" width=\"200px\" padding=\"10px\"   style=\" width:300px; padding: 10px;  \" />\n",
        "  <div class=\"university-details\">\n",
        "    <h2> </h2>\n",
        "    <center><h2>Kerala University of Digital Sciences, Innovation and Technology</h2></center> <h3>(Digital University Kerala, DUK)</h3>\n",
        "    <h4><i><b>School of Digital Sciences</b></i><br></h4>\n",
        "  </div>\n",
        "  <h1>  </h1>\n",
        "  </center>\n",
        "  <h5><b>Date:</b> 11/08/2025 <br>\n",
        "<b>Venue:</b> Room Number 45<br>\n",
        "<b>Topic:</b> Spark Structured Streaming<br>\n",
        "<b>Instructor:</b> Dr. Aswin VS</h5>\n",
        "</body>\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "JqurAPtvLm-F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Spark Structured Streaming"
      ],
      "metadata": {
        "id": "kPwAXN8ktVN-"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4b6774c6"
      },
      "source": [
        "## Introduction to structured streaming\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKvAD7_YTqub"
      },
      "source": [
        "In Spark, **streaming** means processing a continuous, endless flow of data as it arrives, rather than working with a fixed, finite dataset.\n",
        "\n",
        "Think of it as the difference between a **batch job** and a **streaming job**:\n",
        "\n",
        "* A **batch job** is like processing a box of photos you received from a friend; you have all the data upfront, and you process it all at once.\n",
        "* A **streaming job** is like processing photos *as they are being taken* by a camera and sent to you instantly. The data is continuous and has no end.\n",
        "\n",
        "Spark Structured Streaming is a high-level API for building scalable and fault-tolerant streaming applications, introduced in **Spark 2.0**. Spark Structured Streaming is a powerful framework built on top of **Apache Spark SQL** engine that enables processing of live, continuous streams of data in a simple and scalable way. Unlike older streaming systems, it allows us to work with live data using the same DataFrame and Dataset APIs that we already use for batch data. This makes real-time processing much easier to understand and implement.\n",
        "\n",
        "At the heart of Spark Structured Streaming is the idea of treating a stream of data as an **unbounded table**. Imagine you have a table in a database, but instead of being static, new rows are continuously being added as new events arrive. Spark continuously updates the results of queries you define on this table.\n",
        "\n",
        "For example, if you write a query to count the number of words, Spark will keep updating that count whenever new data arrives. This design makes it intuitive because we can write streaming queries just like batch queries, and Spark takes care of the complexities such as scheduling, state management, and fault tolerance in the background.\n",
        "\n",
        "  <img align=\"center\" src=\"https://www.databricks.com/sites/default/files/2020/04/gsasg-spark-streaming-workflow.png\"  width=\"500\"/>\n",
        "\n",
        "<a href=\"https://www.databricks.com/spark/getting-started-with-apache-spark/streaming\" target=\"_blank\">Source</a>\n",
        "\n",
        "\n",
        "### Benefits of Structured Streaming\n",
        "\n",
        "Using Structured Streaming for real-time data processing offers several significant advantages:\n",
        "\n",
        "1.  **Ease of Use:** Leveraging the familiar Spark SQL, DataFrame, and Dataset APIs, developers can write streaming applications with the same concepts and code structures as batch processing. This significantly reduces the learning curve and simplifies development.\n",
        "2.  **Fault Tolerance:** Built on the robust Spark SQL engine, Structured Streaming provides strong fault tolerance guarantees. It can recover from failures without losing data, ensuring reliable processing even in the face of system issues.\n",
        "3.  **End-to-End Exactly-Once Processing:** Structured Streaming guarantees that each input record will affect the final result exactly once, even in the presence of failures or re-processing. This is crucial for applications requiring accurate aggregations and consistent results.\n",
        "4.  **Optimized Execution:** Structured Streaming benefits from Spark SQL's Catalyst optimizer and Tungsten execution engine, providing highly optimized and efficient processing of streaming data.\n",
        "5.  **Unified API:** It unifies batch and streaming processing under a single programming model, making it easier to build applications that can handle both historical and real-time data.\n",
        "\n",
        "### Structured Streaming vs. Spark Streaming (DStreams)\n",
        "\n",
        "Prior to Structured Streaming, Spark's primary streaming API was DStreams (Discretized Streams). While effective, DStreams operated on micro-batches of RDDs, which could be more complex to manage and reason about, especially for stateful computations and fault tolerance.\n",
        "\n",
        "Structured Streaming, by treating data as a continuously appending table, offers a higher-level abstraction. This table-based approach simplifies state management, provides stronger end-to-end guarantees, and integrates seamlessly with the Spark SQL optimizer, leading to improved performance and easier development compared to the RDD-based DStreams.\n",
        "\n",
        "### The Structured Streaming Framework: Sources, Transformations, and Sinks\n",
        "\n",
        "A typical Structured Streaming application involves three main components:\n",
        "\n",
        "1.  **Input Sources:** These are connectors that read data from various streaming sources like Kafka, Kinesis, file systems (for directory monitoring), and sockets. Spark automatically ingests data from these sources and appends it to the conceptual input table.\n",
        "2.  **Transformations:** These are the operations applied to the streaming data, similar to transformations on batch DataFrames. This can include filtering, selecting columns, joining with static or streaming data, aggregating, and more. Spark automatically manages the state for operations like aggregations across time windows.\n",
        "3.  **Output Sinks:** These define where the processed results are written. Common sinks include Kafka, file systems (in various formats), databases (via foreach and foreachBatch), and the console (for debugging). Spark manages writing the output data to the specified sink.\n",
        "\n",
        "By combining these components, you can build powerful real-time data pipelines with Structured Streaming, leveraging the power and simplicity of the Spark SQL engine."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Input Sources\n",
        "\n",
        "Structured Streaming can read data from a variety of sources:\n",
        "\n",
        "* **Files**: Spark can continuously monitor a directory for new files (CSV, JSON, Parquet, etc.) and treat them as incoming streaming data. For example, a folder where log files are constantly generated.\n",
        "\n",
        "* **Kafka**: Kafka is one of the most common sources. It is a distributed messaging system where events (like website clicks, transactions, or sensor readings) are published in real time. Spark can directly connect to Kafka topics and process the incoming messages as a stream.\n",
        "\n",
        "* **Socket**: This is often used for learning and testing. You can connect Spark to a network socket, where data is continuously pushed as text. For example, typing sentences into a terminal and Spark consuming them live.\n",
        "\n",
        "* **Rate Source**: Spark also provides a built-in rate source for testing, which generates data at a specified rate (e.g., rows with timestamps). This is useful for demonstrations or debugging without relying on external data systems.\n",
        "\n",
        "| Source Type | Format Name                              | Example Use Case                                 |\n",
        "| ----------- | ---------------------------------------- | ------------------------------------------------ |\n",
        "| Socket      | `\"socket\"`                               | Simple TCP text stream (dev/demo only)           |\n",
        "| Kafka       | `\"kafka\"`                                | Real-time message queues                         |\n",
        "| File Stream | `\"csv\"`, `\"json\"`, `\"parquet\"`, `\"text\"` | Streaming from directory watch                   |\n",
        "| Rate Source | `\"rate\"`                                 | Generate data at a fixed rows/sec rate (testing) |"
      ],
      "metadata": {
        "id": "GcflVC2R1C1-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Streaming DataFrame/Dataset Concept\n",
        "\n",
        "In Structured Streaming, the main abstraction is a **Streaming DataFrame** (or Dataset in strongly-typed languages like Scala). A Streaming DataFrame is just like a regular DataFrame, except that it represents a continuous flow of data rather than a fixed dataset.\n",
        "\n",
        "For example, when reading from Kafka, you get a DataFrame with columns such as `key`, `value`, `topic`, and `timestamp`. You can then perform operations like `select`, `filter`, or `groupBy` on this DataFrame exactly the same way as with batch data. The key difference is that the results keep getting updated as new data arrives.\n",
        "\n",
        "This makes Structured Streaming very approachable for beginners because there is no need to learn a completely different API. If you know how to query static data with Spark SQL, you can query streaming data with almost the same code."
      ],
      "metadata": {
        "id": "wTn4Xg1W6QJn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Micro-Batching vs. Continuous Processing\n",
        "\n",
        "Structured Streaming can process data in two different modes:\n",
        "\n",
        "* **Micro-Batching**: This is the default mode. Incoming data is grouped into small batches (for example, every 1 second or 5 seconds), and Spark processes each batch as if it were a small dataset. The results are then updated after each batch. Micro-batching provides strong fault tolerance and works well for most real-time use cases.\n",
        "\n",
        "* **Continuous Processing**: In this mode, Spark tries to process data as soon as it arrives, with very low latency (in milliseconds). Unlike micro-batching, it does not wait to collect data into mini-batches. However, this mode is still experimental and does not support all operations.\n",
        "\n",
        "The choice between micro-batching and continuous processing depends on the use case: if ultra-low latency is required, continuous mode may be suitable; otherwise, micro-batching is the safer and more reliable option.\n"
      ],
      "metadata": {
        "id": "w6ffATED6U11"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Event-Time vs. Processing-Time\n",
        "\n",
        "When working with streaming data, timing is very important. Spark distinguishes between two types of time:\n",
        "\n",
        "* **Event-Time**: This refers to the time when the event actually occurred. For example, if a user clicked a link at 10:05 AM, then the event-time of that record is 10:05 AM, even if the data reaches the system later. Event-time is usually recorded in the data itself as a timestamp.\n",
        "\n",
        "* **Processing-Time**: This is the time when Spark actually processes the event. Using the same example, if the click event only reaches Spark at 10:07 AM due to network delays, the processing-time would be 10:07 AM.\n",
        "\n",
        "Handling event-time correctly is crucial in real-world applications, because data can arrive late or out of order. Structured Streaming provides **watermarks** to deal with late-arriving data. For example, you can set a rule to accept late data only if it arrives within 10 minutes of the event-time. This ensures that computations remain accurate without waiting forever for delayed events.\n"
      ],
      "metadata": {
        "id": "MZ0DOBVMz98f"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9e1b8435"
      },
      "source": [
        "## **Lab: Real-Time Word Count with Spark Structured Streaming.**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34fa6fe7"
      },
      "source": [
        "Import the necessary Spark session library and create a SparkSession.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZCFEALQX372a"
      },
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import os\n",
        "import time\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import explode, split, col\n",
        "import plotly.graph_objects as go\n",
        "from IPython.display import clear_output, display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ARsiU2g53_9q"
      },
      "outputs": [],
      "source": [
        "# Create a **`SparkSession`** object, which is the single entry point to use all Spark functionalities, and gives the application a name for identification.\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"StructuredStreamingWordCount\") \\\n",
        "    .getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "bXyf6Mau4DGr"
      },
      "outputs": [],
      "source": [
        "# This code defines a variable for the input folder path and then creates that folder on the file system if it doesn't already exist.\n",
        "\n",
        "input_folder = \"/content/stream_input\"\n",
        "os.makedirs(input_folder, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code\n",
        "* creates a **streaming DataFrame** named `lines` that reads new text files as they arrive in the specified `input_folder`, processing only one new file per trigger.\n",
        "* The code utilizes a series of transformations to deconstruct the input stream and prepare it for aggregation. It first uses the **`split()`** function to tokenize each string by whitespace, creating an array of words. Next, it applies the **`explode()`** function to expand this array, resulting in a new row for each individual word. Finally, it uses **`alias()`** to rename the new column for clarity.\n",
        "* Groups all identical words together and then counts the occurrences of each word to determine its frequency."
      ],
      "metadata": {
        "id": "HFScMgB77ua2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "x2ayKm_x4RR-"
      },
      "outputs": [],
      "source": [
        "lines = spark.readStream \\\n",
        "    .format(\"text\") \\\n",
        "    .option(\"path\", input_folder) \\\n",
        "    .option(\"maxFilesPerTrigger\", 1) \\\n",
        "    .load()\n",
        "\n",
        "# Split lines into words\n",
        "words = lines.select(explode(split(col(\"value\"), \"\\\\s+\")).alias(\"word\"))\n",
        "\n",
        "# Count the words\n",
        "wordCounts = words.groupBy(\"word\").count()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the following code\n",
        "* The function `get_current_counts()` queries the latest streaming results from an in-memory table named `wordCounts` and converts the output into a Pandas DataFrame for display.\n",
        "* The function `write_to_parquet()` writes the latest batch of a streaming DataFrame to a Parquet file, overwriting the file with each new batch to save only the most recent results.\n",
        "* The code in third line initiates a Structured Streaming query that operates in **`complete` output mode**, meaning the entire updated result table is written after each trigger. The query uses **`foreachBatch`** to execute a user-defined function, `write_to_parquet`, on each micro-batch, effectively persisting the full, aggregated `wordCounts` DataFrame to a Parquet file with every update."
      ],
      "metadata": {
        "id": "-Mqs2ctU8skg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ioJXGv_-4YOO"
      },
      "outputs": [],
      "source": [
        "def get_current_counts(query):\n",
        "    # Since Spark does not allow direct collect on stream, use a memory sink for display\n",
        "    result_df = spark.sql(\"SELECT * FROM wordCounts\")\n",
        "    return result_df.toPandas()\n",
        "\n",
        "def write_to_parquet(df, epoch_id):\n",
        "    df.write.mode(\"overwrite\").parquet(\"/content/word_counts\")\n",
        "\n",
        "# Use Spark Structured Streaming with writeStream to memory or parquet\n",
        "query = wordCounts.writeStream \\\n",
        "    .outputMode(\"complete\") \\\n",
        "    .foreachBatch(write_to_parquet) \\\n",
        "    .start()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following `while` loop is a critical component for visualizing the real-time changes in a Spark Streaming application. Here is a breakdown of what the code does:\n",
        "\n",
        "1.  **`while query.isActive`**: This loop continuously runs as long as the streaming query is active. This ensures the dashboard remains live until the user manually stops the stream.\n",
        "2.  **`time.sleep(2)`**: The code pauses for a specified number of seconds to control how frequently the dashboard updates. This prevents constant, rapid refreshes which can be resource-intensive.\n",
        "3.  **`clear_output(wait=True)`**: This function, often used in Jupyter notebooks, clears the previous output. This allows the new graph to be displayed in the same space, creating the illusion of a live, updating dashboard.\n",
        "4.  **`try...except` block**: This robust error handling ensures the loop doesn't crash if the Parquet file doesn't exist yet (for example, at the very beginning of the stream) or if there's a problem reading it.\n",
        "5.  **`counts = pd.read_parquet(\"/content/word_counts\")`**: The code reads the latest word counts from the Parquet file that the streaming query is writing to. Since the query overwrites this file with each new micro-batch, you are always reading the most up-to-date results.\n",
        "6.  **`display(fig)`**: The code uses the `plotly.graph_objects` library to create a bar chart from the `counts` DataFrame and then displays it to the user.\n",
        "\n",
        "To see the live changes, you can copy and paste some `.txt` files into the `/content/stream_input` folder while the code is running.\n",
        "\n",
        "You can create a text file like `text1.txt` with the content \"Hello world from Spark\" and save it to the folder. A few seconds later, you will see the word counts for \"Hello,\" \"world,\" and \"from\" appear in the dashboard. You can then copy and paste another file, like `text2.txt` with the content \"Hello Spark again\" and see the word counts update in real-time."
      ],
      "metadata": {
        "id": "JfeMqtOtJr7n"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "EImAqtET4cTn",
        "outputId": "57e3d95c-ab67-41a6-c0e5-3bb6bb8d63d1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"068e2181-16a7-4db5-9239-0f182443f80e\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"068e2181-16a7-4db5-9239-0f182443f80e\")) {                    Plotly.newPlot(                        \"068e2181-16a7-4db5-9239-0f182443f80e\",                        [{\"x\":[\"showers\",\"traffic\",\"paralysed.\",\"inundated\",\"surrounding\",\"under\",\"in\",\"threw\",\"with\",\"overnight\",\"out\",\"Kolkata\",\"water\",\"life\",\"on\",\"areas\",\"gear\",\"its\",\"Heavy\",\"places\",\"and\",\"of\",\"several\",\"knee-deep\",\"Tuesday,\"],\"y\":[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,1,1,1,1],\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"title\":{\"text\":\"Live Word Count\"},\"xaxis\":{\"title\":{\"text\":\"Words\"}},\"yaxis\":{\"title\":{\"text\":\"Count\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('068e2181-16a7-4db5-9239-0f182443f80e');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "while query.isActive:\n",
        "    time.sleep(2)  # Wait between refresh, adjust as needed\n",
        "    clear_output(wait=True)\n",
        "    try:\n",
        "        # Read the latest counts\n",
        "        import pandas as pd\n",
        "        counts = pd.read_parquet(\"/content/word_counts\")\n",
        "        if counts.empty:\n",
        "            print(\"Waiting for data...\")\n",
        "            continue\n",
        "\n",
        "        fig = go.Figure([go.Bar(x=counts['word'], y=counts['count'])])\n",
        "        fig.update_layout(title=\"Live Word Count\", xaxis_title=\"Words\", yaxis_title=\"Count\")\n",
        "        display(fig)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error or no data yet: {e}\")\n",
        "\n",
        "query.awaitTermination()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Real-Time Use Cases\n",
        "\n",
        "Real-time data processing plays a vital role in many industries where quick decisions can create value or prevent losses. In **finance**, stock prices, market transactions, and currency exchange rates change within milliseconds, so real-time analytics helps in algorithmic trading, portfolio monitoring, and instant risk management. In **e-commerce**, businesses use real-time streams of customer activity—such as clicks, searches, and purchases—to provide personalized recommendations, optimize pricing dynamically, and track inventory instantly. The **Internet of Things (IoT)** generates continuous data from connected devices like sensors, smart meters, and wearables; analyzing this data in real time enables predictive maintenance, energy optimization, and remote monitoring. Similarly, in **fraud detection**, financial institutions and online platforms rely on real-time data to immediately spot unusual patterns, such as abnormal login attempts, suspicious transactions, or identity theft, so that preventive actions can be taken before damage occurs. Together, these use cases highlight how structured streaming systems like Spark enable industries to respond instantly, improve efficiency, and enhance security.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Ka7IKK3yKOqk"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}